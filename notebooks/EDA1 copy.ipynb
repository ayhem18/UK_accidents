{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preeliminary: Import and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "from pathlib import Path\n",
    "print(HOME)\n",
    "\n",
    "HOME_PARENT = Path(HOME).parent\n",
    "import sys\n",
    "sys.path.append(str(HOME_PARENT))\n",
    "sys.path.append(os.path.join(HOME_PARENT, 'scripts'))\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "CA_PATH = os.path.join(HOME_PARENT, 'data', 'casualities.csv')\n",
    "ACC_PATH = os.path.join(HOME_PARENT, 'data', 'accidents.csv')\n",
    "VE_PATH = os.path.join(HOME_PARENT, 'data', 'vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the data as needed\n",
    "ACC = pd.read_csv(ACC_PATH)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the number data suggested by the 3 tables, we can see that the best way to combine the data available is to predict the casuality severity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data: a dive into the data's documentation \n",
    "## Accidents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through the explanations of the fields, it is possible to reduce the number of features as some of them do not introduce any additional value for our predictive task.  \n",
    "The following will be dropped:  \n",
    "1. Location Easting OSGR (Null if not known)\n",
    "2. Location Northing OSGR (Null if not known)    \n",
    "These values represent the location of the accident with respect to a local geospatial system\n",
    "3. The police attendance\n",
    "4. Longitude and Latitude might be dropped as the data is already clustered into different districts\n",
    "5. Accident Severity: this value is practically equivalent to the target: the severity of casualities\n",
    "6. Police: The police's intervention takes place generally after the accident. Such intervention could not possible affect the accident's severity and the casualities' seriousness "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional remarks:\n",
    "* The most seemingly important features are:\n",
    "    1. 1st /2nd  Road Class / if it reflects quality\n",
    "    2. weather conditions / Light Conditions\n",
    "    3. Pedestrian Crossing Human control: we don't expect many accidents in conjuctions controlled by police officer: HOWEVER IT MIGHT HAVE SOME OVERLAPPING WITH CONJUNCTION CONTROL\n",
    "    4. Urban / Rural area: Rural area are more likely to have more fatal accidents: more serious casualities\n",
    "    5. SPEED LIMIT\n",
    "These observations are to confirmed to denied through the EDA.\n",
    "* geospatial information should be processed further or dropped\n",
    "* The temporal data might be reduced to either the month or the year values if needed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The vehicles\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The data provides a detailed description of the vehicle\n",
    "* The fields most likely should be combined into a fewer but more general representations\n",
    "* Certain fields might be dropped:\n",
    "    1. Vehicle Location: can be deduced to a certain extent by the type of the road / location the accident took place\n",
    "    2. Vehicle Maneouver is to be dropped\n",
    "    3. There are two Hit Object features that can be merged into one\n",
    "    4. The IMD level as well as the home area of the driver do not seem to have direct relation with the seriousness of the casuality\n",
    "    5. any information about the driver can be found in the casuality table, so it should be dropped from the vehicle table \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data: a dive into the code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The accidents table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's start with removing the unncessary data\n",
    "ACC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_drop_cols = ['Location_Easting_OSGR', 'Location_Northing_OSGR','Police_Force', 'Did_Police_Officer_Attend_Scene_of_Accident', 'LSOA_of_Accident_Location', 'Number_of_Casualties']\n",
    "ACC.drop(columns=acc_drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's provide better names (and mainly shorter) for the featrures\n",
    "new_acc_cols = {'Longitude': 'lng', 'Latitude': 'lat', 'Accident_Severity': 'y', 'Number_of_Vehicles': 'n_vehs', 'Local_Authority_(District)': 'district',\n",
    "                'Local_Authority_(Highway)': 'highway', '1st_Road_Class': 'road_c1', '1st_Road_Number': 'road_n1', 'Road_Type':'road_type'\n",
    "                , 'Light_Conditions': 'light', 'Weather_Conditions': 'weather', 'Road_Surface_Conditions': 'road_surface', 'Urban_or_Rural_Area': 'area_type'\n",
    "                , \"Junction_Detail\": \"junc_detail\", \"Junction_Control\": \"junc_control\", \"2nd_Road_Class\": \"road_c2\", \"2nd_Road_Number\": \"road_n2\", \n",
    "                \"Pedestrian_Crossing-Human_Control\": \"cross_control\", \"Pedestrian_Crossing-Physical_Facilities\": \"cross_facilities\", \n",
    "                \"Special_Conditions_at_Site\": \"special_conds\", \"Carriageway_Hazards\": \"hazards\"}\n",
    "\n",
    "from df_operations import new_col_names, to_columns\n",
    "ACC = new_col_names(new_acc_cols, ACC)\n",
    "# make sure to convert them to lowercase\n",
    "ACC = to_columns(ACC, lambda c: c.lower().strip()) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACC: Explatory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's split the data\n",
    "from df_operations import get_col_types, draw_unique_data_table, draw_missing_data_table\n",
    "num_cols, cat_cols = get_col_types(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_unique_data_table(ACC)\n",
    "# let's start with a small number of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.clf()\n",
    "acc_cat = ACC.loc[:, cat_cols]\n",
    "\n",
    "small_cats = [c for c in  cat_cols if len(acc_cat[c].value_counts()) <= 10]\n",
    "print(len(small_cats))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(4, 4,figsize=(20, 16), sharex=False, sharey=False)\n",
    "for i, f in enumerate(small_cats):  \n",
    "    chart = sns.histplot(ax=axes[i // 4, i % 4], data=acc_cat, x=f, stat='percent')\n",
    "    # chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following procedure will be used:\n",
    "# if a certain value of a categorical variable does not correlate with fatal accidents: (a mere 2% of the total accidents), then this feature will either be dropped, or \n",
    "# the values will be rearranged\n",
    "import numpy as np\n",
    "\n",
    "def cat_feat_distribution(df: pd.DataFrame, feature: str, n_unique_as_discrete=20):\n",
    "    assert feature in df.columns\n",
    "    # make sure the indeed categorical\n",
    "    assert feature not in set(list(df.select_dtypes(np.number).columns)) or len(df[feature].value_counts()) <= n_unique_as_discrete \n",
    "\n",
    "    return (df[feature].value_counts() / len(df))\n",
    "\n",
    "for c in small_cats:\n",
    "    print(cat_feat_distribution(acc_cat, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acc_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visual as v\n",
    "# now it is interesting to understand the conditional probabitili\n",
    "\n",
    "# for c in small_cats:\n",
    "#     figure, axes = plt.subplots(1, 2, figsize=(18, 6), sharex=False, sharey=False)\n",
    "#     # first display distribution\n",
    "#     distribution = sns.histplot(ax=axes[0], data=acc_cat, x=c, stat='percent')\n",
    "#     # second display the condition distribution of the categorical feature over the target variable\n",
    "#     con_dis = v.visualize_cond_prob(acc_cat, target='y', hue=c, show=False)\n",
    "#     axes[1] = con_dis\n",
    "\n",
    "#     # con_dis_2 = v.visualize_cond_prob(acc_cat, target=c, hue='y', show=False)\n",
    "#     # axes[2] = con_dis_2\n",
    "\n",
    "#     plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the day of the week does not seem to affect the seriousness of the casuality\n",
    "ACC.drop(columns=['day_of_week', 'y', 'n_vehs'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make sure to convert the date to a datetime4\n",
    "# first convert all dates to the same format\n",
    "\n",
    "from  datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def uniform_date_format(date_text:str):\n",
    "    try:\n",
    "        return datetime.strptime(date_text, '%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        pass\n",
    "    # first parse the date as it is\n",
    "    dt = parse(date_text)\n",
    "    return dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# first make sure to unify the date's format\n",
    "ACC['date'] = ACC['date'].apply(uniform_date_format)\n",
    "# convert all the strings to date time objects\n",
    "ACC['date'] = pd.to_datetime(ACC['date'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one final important step to do is to convert the textual indices\n",
    "ACC.reset_index(inplace=True)\n",
    "# create a map to map each old accident_index to the new index\n",
    "old_to_index_map = dict([(old, new) for old, new in zip(ACC['accident_index'].tolist(), ACC['index'].tolist())])\n",
    "ACC.drop(columns='accident_index', inplace=True)\n",
    "ACC = ACC.rename(columns={\"index\": \"accident_index\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the resulting accidents table\n",
    "processed_data_dir = os.path.join(HOME_PARENT, 'data', 'preprocessed_data')\n",
    "os.makedirs(processed_data_dir, exist_ok=True)\n",
    "ACC.to_csv(os.path.join(processed_data_dir, 'accidents_v1.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Vehicles Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE = pd.read_csv(VE_PATH)\n",
    "VE = to_columns(VE, lambda x: x.lower().strip())\n",
    "print(VE.columns)\n",
    "COLUMNS_TO_REMOVE = ['vehicle_manoeuvre', 'vehicle_location-restricted_lane', 'junction_location', 'was_vehicle_left_hand_drive?', \n",
    "                     'journey_purpose_of_driver', 'sex_of_driver', 'age_of_driver','age_band_of_driver', 'propulsion_code',\n",
    "                     'driver_imd_decile', 'driver_home_area_type']\n",
    "\n",
    "VE.drop(columns=COLUMNS_TO_REMOVE, inplace=True)\n",
    "VE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE.columns\n",
    "# renaming the columns\n",
    "NEW_VEH_NAMES = {\"accident_index\": \"acc_index\", \"vehicle_reference\": \"veh_ref\", \"vehicle_type\": \"veh_type\", \"towing_and_articulation\": \"towing\",\n",
    "                 \"skidding_and_overturning\": \"reversed\", \"hit_object_in_carriageway\": \"object_in\", \"vehicle_leaving_carriageway\": \"veh_left\", \n",
    "                 \"hit_object_off_carriageway\": \"object_out\", '1st_point_of_impact':\"impact\",\"engine_capacity_(cc)\": \"cc\", \"age_of_vehicle\": \"veh_age\"}\n",
    "\n",
    "VE = new_col_names(NEW_VEH_NAMES, VE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE['acc_index'] = VE['acc_index'].apply(lambda x: old_to_index_map[x]) \n",
    "assert set(VE['acc_index']).issubset(ACC['accident_index'])\n",
    "assert len(VE['acc_index'].value_counts()) == len(ACC)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE vehicle table does not have a unique reference for the car. The primary key is veh_ref + acc_index. To load this data to a database, the veh_ref should be modified to uniquely reprsent the car: a simple merge of veh_ref and accident_index would do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(VE['veh_ref']))\n",
    "print(min(VE['veh_ref']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_veh_ref(row):\n",
    "    row['veh_ref'] = row['acc_index'] * 91 + row['veh_ref'] \n",
    "    return row\n",
    "\n",
    "VE = VE.apply(fix_veh_ref, axis=1)\n",
    "assert all(VE['veh_ref'].value_counts() == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VE.to_csv(os.path.join(processed_data_dir, 'vehicles_v1.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The casualities Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA = pd.read_csv(CA_PATH)\n",
    "CA.columns = [c.lower() for c in CA.columns]\n",
    "print(CA.columns)\n",
    "# drop the last 6 columns\n",
    "CA.drop(columns=list(CA.columns)[-6:] + ['casualty_reference'], inplace=True)\n",
    "CA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's fix the naming here\n",
    "CA_NEW_NAMES = {\"accident_index\": \"acc_index\", \"vehicle_reference\": \"veh_ref\", 'casualty_class': \"cas_type\",\"sex_of_casualty\": \"cas_sex\", \n",
    "                'age_of_casualty': \"cas_age\", 'age_band_of_casualty': \"cas_age_band\", 'casualty_severity': \"cas_y\", 'pedestrian_location': \"ped_loc\"}\n",
    "\n",
    "CA = new_col_names(CA_NEW_NAMES, CA)\n",
    "CA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as it does not seem possible to make a primary key for each casualty out of the provided data\n",
    "# we can create a simple serieal key by resetting the index\n",
    "CA.reset_index(inplace=True)\n",
    "CA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA['acc_index'] = CA['acc_index'].apply(lambda x: old_to_index_map[x]) \n",
    "assert set(CA['acc_index']) == set(ACC['accident_index'])\n",
    "assert len(CA['acc_index'].value_counts()) == len(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same modification applied on the vehicle file should be applied to that of casualties\n",
    "CA = CA.apply(fix_veh_ref, axis=1)\n",
    "assert set(CA['veh_ref']).issubset(set(VE['veh_ref']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA.to_csv(os.path.join(processed_data_dir, 'casualties_v1.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Namesless Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accident_index', 'lng', 'lat', 'date', 'district', 'road_c1',\n",
      "       'road_n1', 'road_type', 'speed_limit', 'junc_detail', 'junc_control',\n",
      "       'road_c2', 'road_n2', 'cross_control', 'cross_facilities', 'light',\n",
      "       'weather', 'road_surface', 'special_conds', 'hazards', 'area_type'],\n",
      "      dtype='object')\n",
      "Index(['index', 'acc_index', 'veh_ref', 'cas_type', 'cas_sex', 'cas_age',\n",
      "       'cas_age_band', 'cas_y', 'ped_loc'],\n",
      "      dtype='object')\n",
      "Index(['acc_index', 'veh_ref', 'veh_type', 'towing', 'reversed', 'object_in',\n",
      "       'veh_left', 'object_out', 'impact', 'cc', 'veh_age'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print\n",
    "processed_data_dir = os.path.join(Path(os.getcwd()).parent, 'data', 'preprocessed_data')\n",
    "# let's get this shit done by today!!\n",
    "ACC = pd.read_csv(os.path.join(processed_data_dir, 'accidents_v1.csv'))\n",
    "CA = pd.read_csv(os.path.join(processed_data_dir, 'casualties_v1.csv'))\n",
    "VEH = pd.read_csv(os.path.join(processed_data_dir, 'vehicles_v1.csv'))\n",
    "\n",
    "print(ACC.columns)\n",
    "print(CA.columns)\n",
    "print(VEH.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident_index        int64\n",
      "lng                 float64\n",
      "lat                 float64\n",
      "date                 object\n",
      "district              int64\n",
      "road_c1               int64\n",
      "road_n1               int64\n",
      "road_type             int64\n",
      "speed_limit           int64\n",
      "junc_detail           int64\n",
      "junc_control          int64\n",
      "road_c2               int64\n",
      "road_n2               int64\n",
      "cross_control         int64\n",
      "cross_facilities      int64\n",
      "light                 int64\n",
      "weather               int64\n",
      "road_surface          int64\n",
      "special_conds         int64\n",
      "hazards               int64\n",
      "area_type             int64\n",
      "dtype: object\n",
      "\n",
      "index           int64\n",
      "acc_index       int64\n",
      "veh_ref         int64\n",
      "cas_type        int64\n",
      "cas_sex         int64\n",
      "cas_age         int64\n",
      "cas_age_band    int64\n",
      "cas_y           int64\n",
      "ped_loc         int64\n",
      "dtype: object\n",
      "\n",
      "acc_index     int64\n",
      "veh_ref       int64\n",
      "veh_type      int64\n",
      "towing        int64\n",
      "reversed      int64\n",
      "object_in     int64\n",
      "veh_left      int64\n",
      "object_out    int64\n",
      "impact        int64\n",
      "cc            int64\n",
      "veh_age       int64\n",
      "dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# let's check the types \n",
    "print(ACC.dtypes, end='\\n' * 2)\n",
    "print(CA.dtypes, end='\\n' * 2)\n",
    "print(VEH.dtypes, end='\\n' * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC.drop(columns=['highway', 'time'], inplace=True)\n",
    "ACC.to_csv(os.path.join(processed_data_dir, 'accidents_v1.csv'), index=False) \n",
    "ACC.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
